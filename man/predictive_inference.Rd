% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/predictive.R
\name{predictive_inference}
\alias{dpred}
\alias{ppred}
\alias{predictive_inference}
\alias{qpred}
\alias{rpred}
\title{Predictive inference for the largest value observed in N years.}
\usage{
dpred(ev_obj, x, n_years = 100, npy = NULL, log = FALSE)

ppred(ev_obj, q, n_years = 100, npy = NULL, lower_tail = TRUE)

qpred(ev_obj, p, n_years = 100, npy = NULL, lower_tail = TRUE)

rpred(ev_obj, n_years = 100, npy = NULL)
}
\arguments{
\item{ev_obj}{An object of class "evpost", a result of a call to
\code{\link{rpost}} with \code{model = "gev"}, \code{model = "os"},
\code{model = "pp"} or \code{model == "bingp"}.  Calling these functions
after a call to \code{rpost} with \code{model == "gp"} will produce an
error, because inferences about the probability of threshold exceedance
are required, in addition to the distribution of threshold excesses.
The model is stored in \code{ev_obj$model}.}

\item{x, q}{Numeric vectors of quantiles.  If \code{ev_obj$model == "bingp"}
then no element of \code{x} and \code{q} can be less than the
threshold \code{ev_obj$thresh}.}

\item{n_years}{A numeric vector. Values of N.}

\item{npy}{A numeric scalar. The mean number of observations per year
  of data, after excluding any missing values, i.e. the number of
  non-missing observations divided by total number of years of non-missing
  data.

If \code{rpost} was called with \code{model == "bingp"} then \code{npy}
must either have been supplied in that call or be supplied here.
If \code{npy} is supplied twice then the value supplied here will be
used and a warning given.

Otherwise, a default value will be assumed if \code{npy} is not supplied,
based on the value of \code{model} in the call to \code{rpost}:
\itemize{
  \item{\code{model = "gev"}:} \code{npy} = 1, i.e. the data were
    annual maxima so the block size is one year.
  \item{\code{model = "os"}:} \code{npy} = 1, i.e. the data were
    annual order statistics so the block size is one year.
  \item{\code{model = "pp"}:}
    \code{npy} = \code{length(x$data)} / \code{noy},
    i.e. the value of \code{noy} used in the call to \code{\link{rpost}}
    is equated to a block size of one year.
}}

\item{log}{A logical scalar.  If TRUE the log-density is returned.}

\item{lower_tail}{A logical scalar.  If TRUE (default), probabilities
are P[X <= x], otherwise, P[X > x].}

\item{p}{A numeric vector of probabilities in (0,1).  If
\code{ev_obj$model == "bingp"} then no element of \code{p} can be less
than the value of \code{ppred(ev_obj, q = ev_obj$thresh)}, i.e.
\code{p} cannot correspond to a predictive quantile that is below the
threshold.}
}
\value{
\itemize{
  \item{\code{pred_dgev:}} A \code{length(x)} by \code{length(n_years)}
  matrix.  Column i contains the predictive density function
  of the \code{n_years[i]} maxiumum evaluated at the values in \code{x}.
  \item{\code{pred_pgev:}} A \code{length(q)} by \code{length(n_years)}
  matrix.  Column i contains the predictive distribution function
  of the \code{n_years[i]} maxiumum evaluated at the values in \code{q}.
  \item{\code{pred_qgev:}} A \code{length(p)} by \code{length(n_years)}
  matrix.  Column i contains the predictive quantiles of the
  \code{n_years[i]} maxiumum evaluated at the probabilities in \code{p} .
  \item{\code{pred_rgev:}} An \code{nrow(ev_obj$sim_vals)} by
  \code{length(n_years)} matrix.  Column i contains
  \code{nrow(ev_obj$sim_vals)} vaues simulated from the predictive
  distribution of the \code{n_years[i]} maxiumum.
}
}
\description{
Density function, distribution function, quantile function and
random generation for the largest value observed in N years using
Bayesian (posterior) predictive inference.
}
\details{
Inferences about future extreme observations are integrated over
  the posterior distribution of the model parameters, thereby accounting
  for uncertainty in model parameters and uncertainty owing to the
  variability of future observations.  In practice the integrals involved
  are estimated using an empirical mean over the posterior sample.
  See, for example,
  \href{http://dx.doi.org/10.1007/978-1-4471-3675-0_9}{Coles (2001),
  chapter 9},
  \href{http://dx.doi.org/10.1201/b19721-14}{Stephenson (2016)}
  or
  \href{http://dx.doi.org/10.1111/rssc.12159}{Northrop et al. (2017)}
  for details.

  \strong{GEV / OS / PP}.
  If \code{model = "gev"}, \code{model = "os"} or \code{model = "pp"}
  in the call to \code{\link{rpost}} then we calculate the number
  of blocks in \code{n_years} years, and then convert the posterior
  simulated GEV parameters to the \code{n_years} level of aggregation.

  In \code{dpred} we calculate using \code{\link{dgev}}
  the GEV density at \code{x} for each of the posterior samples
  of the location, scale and shape parameters.  Then we take the
  mean of these values.

  In \code{ppred} we calculate using \code{\link{pgev}}
  the GEV density at \code{q} for each of the posterior samples
  of the location, scale and shape parameters.  Then we take the
  mean of these values.

  In \code{qpred} we first calculate initial estimates of the
  required predictive quantiles by calculating using \code{\link{qgev}}
  the GEV density at \code{p} for each of the posterior samples
  of the location, scale and shape parameters and taking the
  mean of these values.  Then we solve \code{ppred}(q) = \code{p[i]}
  numerically for q for each element \code{p[i]} of \code{p}.

  In \code{rpred} for each simulated value of the GEV parameters
  at the \code{n_years} level of aggregation we simulate one value from
  this GEV distribution using \code{\link{rgev}}.  Thus, each sample
  from the predictive distribution is of a size equal to the size of
  the posterior sample.

  \strong{Binomial-GP}.  If \code{model = "bingp"} in the call to
  \code{\link{rpost}} then we calculate the mean number of observations
  in \code{n_years} years, i.e. \code{npy * n_years}.

  Let \eqn{M_N} be the largest value observed in \eqn{N} years,
  \eqn{m} = \code{npy * n_years} and \eqn{u} the threshold
  \code{ev_obj$thresh} used in the call to \code{rpost}.
  For fixed values of \eqn{\theta = (p, \sigma, \xi)} the distribution
  function of \eqn{M_N} is given by \eqn{F(z, \theta)^m}, for
  \eqn{z >= u}, where
  \deqn{F(z, \theta) = 1 - p * [1 + \xi (x - u) / \sigma] ^ (-1/\xi).}
  The distribution function of \eqn{M_N} cannot be evaluated for
  \eqn{z < u} because no model has been supposed for observations below
  the threshold.

  In \code{ppred} we calculate \eqn{F(z, \theta)^m} at \code{q} for
  each of the posterior samples \eqn{\theta}.  Then we take the
  mean of these values.

  In \code{dpred} we calculate the density of of \eqn{M_n}, i.e. the
  derivative of \eqn{F(z, \theta)^m} with respect to \eqn{z} at \code{x}
  for each of the posterior samples \eqn{\theta}.  Then we take the
  mean of these values.

  In \code{qpred} we perform a calculation that is analogous to the
  GEV case above, i.e. we solve \code{ppred}(q) = \code{p[i]}
  numerically for q for each element \code{p[i]} of \code{p}.

  In \code{rpred} for each simulated value of the bin-GP parameters
  we simulate from the distribution of \eqn{M_N} using the inversion
  method applied to the distribution function of \eqn{M_N} given above.
  Occasionally a value below the threshold would need to be simulated.
  If these instances a missing value code \code{NA} is returned.
  Thus, each sample from the predictive distribution is of a size equal
  to the size of the posterior sample.
}
\examples{
# GEV
data(portpirie)
mat <- diag(c(10000, 10000, 100))
pn <- set_prior(prior = "norm", model = "gev", mean = c(0,0,0), cov = mat)
gevp  <- rpost(n = 1000, model = "gev", prior = pn, data = portpirie)

q <- seq(4, 7, 0.1)
dpred(gevp, x = q)
dpred(gevp, q, n_years = c(100, 1000))
ppred(gevp, q = q)
ppred(gevp, q, n_years = c(100, 1000))
p <- c(0.025, 0.25, 0.5, 0.75, 0.975)
qq <- qpred(gevp, p)
ppred(gevp, qq)
qpred(gevp, p, n_years = c(100, 1000))

sim1 <- rpred(gevp)
sim2 <- pred_rgev(gevp, n_years = c(100, 1000))

# Binomial-GP
data(gom)
u <- quantile(gom, probs = 0.65)
fp <- set_prior(prior = "flat", model = "gp", min_xi = -1)
bp <- set_bin_prior(prior = "jeffreys")
npy_gom <- length(gom)/105
gpg1 <- rpost(n = 1000, model = "bingp", prior = fp, thresh = u, data = gom,
             bin_prior = bp)

q <- seq(10, 30, 0.1)
# Setting npy in call to ppred(), for example.
ppred(gpg1, q = q, npy = npy_gom)

# Setting npy in call to rpost()
gpg2 <- rpost(n = 1000, model = "bingp", prior = fp, thresh = u, data = gom,
             bin_prior = bp, npy = npy_gom)
ppred(gpg2, q = q)
dpred(gpg2, x = q)
p <- c(0.025, 0.25, 0.5, 0.75, 0.975)
qpred(gpg2, p = p)

sim1 <- rpred(gpg2)
sim2 <- rpred(gpg2, n_years = c(100, 1000))
}
\references{
Coles, S. G. (2001) \emph{An Introduction to Statistical
  Modeling of Extreme Values}, Springer-Verlag, London.
  Chapter 9: \url{http://dx.doi.org/10.1007/978-1-4471-3675-0_9}

Northrop, P. J., Attalides, N. and Jonathan, P. (2017)
  Cross-validatory extreme value threshold selection and uncertainty
  with application to ocean storm severity.
  \emph{Journal of the Royal Statistical Society Series C: Applied
  Statistics}, \emph{66}(1), 93-120.
  \url{http://dx.doi.org/10.1111/rssc.12159}

Stephenson, A. (2016). Bayesian Inference for Extreme Value
  Modelling. In \emph{Extreme Value Modeling and Risk Analysis: Methods and
  Applications}, edited by D. K. Dey and J. Yan, 257-80. London:
  Chapman and Hall. \url{http://dx.doi.org/10.1201/b19721-14}
  value posterior using the evdbayes package.
}

